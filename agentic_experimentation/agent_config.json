{
  "repo_root": "..",
  "ideas_file": "agentic_experimentation\\ideas.txt",
  "sweep_command": "python adaptive_vol_momentum.py",
  "sweep_cwd": ".",
  "results_csv": "C:\\Users\\micha\\myhome\\algo\\artifacts\\period_returns\\meta_config_sweep_results.csv",
  "baseline_csv": "agentic_experimentation\\baselines\\meta_config_sweep_results_baseline.csv",
  "base_on_working_tree": true,
  "keep_worktrees": false,
  "worktree_root": "agentic_experimentation\\worktrees",
  "experiments_root": "agentic_experimentation\\experiments",
  "test_command": null,
  "test_cwd": ".",
  "prompts": {
    "planner": "agentic_experimentation\\prompts\\planner\\planner_prompt.txt",
    "coder": "agentic_experimentation\\prompts\\coder\\coder_prompt.txt",
    "reviewer": "agentic_experimentation\\prompts\\reviewer\\reviewer_prompt.txt",
    "planner_system": "agentic_experimentation\\prompts\\planner\\planner_system.txt",
    "coder_system": "agentic_experimentation\\prompts\\coder\\coder_system.txt",
    "reviewer_system": "agentic_experimentation\\prompts\\reviewer\\reviewer_system.txt",
    "patch": "agentic_experimentation\\prompts\\patch_prompt.txt",
    "planner_repo_files": "agentic_experimentation\\prompts\\planner\\planner_repo_files.txt",
    "coder_repo_files": "agentic_experimentation\\prompts\\coder\\coder_repo_files.txt",
    "reviewer_repo_files": "agentic_experimentation\\prompts\\reviewer\\reviewer_repo_files.txt"
  },
  "agents": {
    "planner": {
      "provider": "dummy",
      "model": "gpt-4.1",
      "temperature": 0.2,
      "max_tokens": 1200,
      "timeout_sec": 60
    },
    "coder": {
      "provider": "dummy",
      "model": "gpt-4.1",
      "temperature": 0.2,
      "max_tokens": 1200,
      "timeout_sec": 60
    },
    "reviewer": {
      "provider": "dummy",
      "model": "gemini-1.5-pro",
      "temperature": 0.2,
      "max_tokens": 1200,
      "timeout_sec": 60
    }
  },
  "llm": {
    "provider": "dummy",
    "model": "gpt-4.1",
    "api_key_env": "OPENAI_API_KEY",
    "base_url": "",
    "timeout_sec": 60,
    "max_tokens": 1200,
    "temperature": 0.2,
    "dummy_idea_text": "IDEA: Increase top_n_global by a small amount to test sensitivity.\nRATIONALE: Tests robustness to selection breadth.\nFILES: adaptive_vol_momentum.py\nRISKS: Might dilute signal if too large.",
    "dummy_patch_mode": "noop",
    "dummy_patch_path": "agentic_experimentation\\examples\\sample_patch.diff"
  },
  "scoring": {
    "score_column": "CHANGE_ME",
    "higher_is_better": true
  }
}
