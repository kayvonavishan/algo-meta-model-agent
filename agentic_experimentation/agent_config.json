{
  "repo_root": "..",
  "ideas_file": "agentic_experimentation\\ideas.txt",
  "sweep_command": "python adaptive_vol_momentum.py",
  "sweep_cwd": ".",
  "results_csv": "C:\\Users\\micha\\myhome\\algo\\artifacts\\period_returns\\meta_config_sweep_results.csv",
  "baseline_csv": "agentic_experimentation\\baselines\\meta_config_sweep_results_baseline.csv",
  "agentic_output_root": "C:\\Users\\micha\\myhome\\algo\\artifacts\\period_returns\\agentic",
  "base_on_working_tree": true,
  "keep_worktrees": false,
  "worktree_root": "agentic_experimentation\\worktrees",
  "experiments_root": "agentic_experimentation\\experiments",
  "test_command": null,
  "test_cwd": ".",
  "test_pattern": "tests/test_smoke_invariants.py tests/test_statistical_sanity.py",
  "prompts": {
    "planner": "agentic_experimentation\\prompts\\planner\\planner_prompt.txt",
    "coder": "agentic_experimentation\\prompts\\coder\\coder_prompt.txt",
    "reviewer": "agentic_experimentation\\prompts\\reviewer\\reviewer_prompt.txt",
    "planner_system": "agentic_experimentation\\prompts\\planner\\planner_system.txt",
    "coder_system": "agentic_experimentation\\prompts\\coder\\coder_system.txt",
    "reviewer_system": "agentic_experimentation\\prompts\\reviewer\\reviewer_system.txt",
    "patch": "agentic_experimentation\\prompts\\patch_prompt.txt",
    "planner_repo_files": "agentic_experimentation\\prompts\\planner\\planner_repo_files.txt",
    "coder_repo_files": "agentic_experimentation\\prompts\\coder\\coder_repo_files.txt",
    "reviewer_repo_files": "agentic_experimentation\\prompts\\reviewer\\reviewer_repo_files.txt"
  },
  "agents": {
    "planner": {
      "provider": "openai",
      "model": "gpt-5.2",
      "reasoning": "high",
      "temperature": 0.2,
      "max_tokens": 1200,
      "timeout_sec": 60
    },
    "coder": {
      "provider": "openai",
      "model": "gpt-5.2-codex",
      "reasoning": "high",
      "temperature": 0.2,
      "max_tokens": 1200,
      "timeout_sec": 60
    },
    "reviewer": {
      "provider": "openai",
      "model": "gpt-5.2",
      "reasoning": "high",
      "temperature": 0.2,
      "max_tokens": 1200,
      "timeout_sec": 60
    }
  },
  "scoring": {
    "score_column": "CHANGE_ME",
    "higher_is_better": true
  }
}
